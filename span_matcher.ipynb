{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from ipywidgets import HTML\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_text = \"Bei der Auslegung einer Willenserklärung ist der wirkliche Wille zu erforschen und nicht an dem buchstäblichen Sinn der Worte ist zu haften, d.h. ohne daran zu haften.\"\n",
    "\n",
    "blank_de = textacy.make_spacy_doc(de_text, lang='de_core_news_lg')\n",
    "de_doc = blank_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f9bc440d1e498f9632b481459eeb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<strong>ist der wirkliche Wille zu erforschen</strong> (<code>zu__inf__sein</code>)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b12e12a194d8c9d7e97fda3a128d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<strong>ist zu haften</strong> (<code>zu__inf__sein</code>)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8350d3b22632473d805b435830112a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<strong>ohne daran zu haften</strong> (<code>ohne_zu__inf</code>)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'ohne_zu__inf'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m\n\u001b[0;32m     69\u001b[0m     de_doc\u001b[39m.\u001b[39mspans[\u001b[39m'\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(span)\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(\"Noun phrases:\", '\\n'.join([chunk.text for chunk in de_doc.noun_chunks]), sep='\\n' + '-'*25 +'\\n', end='\\n\\n')\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m# print(de_doc.spans['custom'])\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mohne zu _inf_:\u001b[39m\u001b[39m'\u001b[39m, [de_doc[start:end]\u001b[39m.\u001b[39;49mtext \u001b[39mfor\u001b[39;49;00m _, start, end \u001b[39min\u001b[39;49;00m matches \u001b[39mif\u001b[39;49;00m de_doc[start:end]\u001b[39m.\u001b[39;49m_\u001b[39m.\u001b[39;49mohne_zu__inf])\n\u001b[0;32m     75\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mzu _inf_ sein:\u001b[39m\u001b[39m'\u001b[39m, [de_doc[start:end]\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m _, start, end \u001b[39min\u001b[39;00m matches \u001b[39mif\u001b[39;00m de_doc[start:end]\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mzu__inf__sein])\n\u001b[0;32m     77\u001b[0m \u001b[39m# print('ohne zu _inf_:', list(set([span.text for span in de_doc.spans['custom'] if span._.ohne_zu__inf])))\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m# print('zu _inf_ sein:', list(set([span.text for span in de_doc.spans['custom'] if span._.zu__inf__sein])))\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[39m# custom spans\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     69\u001b[0m     de_doc\u001b[39m.\u001b[39mspans[\u001b[39m'\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(span)\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(\"Noun phrases:\", '\\n'.join([chunk.text for chunk in de_doc.noun_chunks]), sep='\\n' + '-'*25 +'\\n', end='\\n\\n')\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m# print(de_doc.spans['custom'])\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mohne zu _inf_:\u001b[39m\u001b[39m'\u001b[39m, [de_doc[start:end]\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m _, start, end \u001b[39min\u001b[39;00m matches \u001b[39mif\u001b[39;00m de_doc[start:end]\u001b[39m.\u001b[39;49m_\u001b[39m.\u001b[39;49mohne_zu__inf])\n\u001b[0;32m     75\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mzu _inf_ sein:\u001b[39m\u001b[39m'\u001b[39m, [de_doc[start:end]\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m _, start, end \u001b[39min\u001b[39;00m matches \u001b[39mif\u001b[39;00m de_doc[start:end]\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mzu__inf__sein])\n\u001b[0;32m     77\u001b[0m \u001b[39m# print('ohne zu _inf_:', list(set([span.text for span in de_doc.spans['custom'] if span._.ohne_zu__inf])))\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m# print('zu _inf_ sein:', list(set([span.text for span in de_doc.spans['custom'] if span._.zu__inf__sein])))\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[39m# custom spans\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimboump\\workspace\\eleto-2023\\venv\\Lib\\site-packages\\spacy\\tokens\\underscore.py:47\u001b[0m, in \u001b[0;36mUnderscore.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extensions:\n\u001b[1;32m---> 47\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE046\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n\u001b[0;32m     48\u001b[0m     default, method, getter, setter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extensions[name]\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m getter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'ohne_zu__inf'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "# import Matcher and rewrite the previous code using it, to print the same results\n",
    "from spacy.matcher import Matcher\n",
    "from ipywidgets import HTML\n",
    "\n",
    "matcher = Matcher(de_doc.vocab)\n",
    "\n",
    "def add_span_attributes(matcher, doc, i, matches, span_attrs=None):\n",
    "    match_id, start, end = matches[i]\n",
    "    label_ = doc.vocab.strings[match_id]\n",
    "    span = Span(doc, start, end, label=label_)\n",
    "    # span.set_extension(label_, getter=lambda x: True if span.label == label_ else False,\n",
    "    #                    force=True)\n",
    "    doc.ents = textacy.extract.entities(doc)\n",
    "    print(doc.ents)\n",
    "    if span_attrs:\n",
    "        for attr, val in span_attrs.items():\n",
    "            setattr(span._, attr, val)\n",
    "\n",
    "# def clean_matches_on_match(matcher, doc, i, matches):\n",
    "#     unique_matches = []\n",
    "#     for match_text, start, end in matches:\n",
    "#         if start not in [start for _, start, end in unique_matches]:\n",
    "#             unique_matches.append((match_text, start, end))\n",
    "#     match_id, start, end = unique_matches[i]\n",
    "#     span = Span(doc, start, end, label=match_id, span_id=match_id)\n",
    "#     doc.ents = list(doc.ents) + [span] if span not in doc.ents else [doc.ents]\n",
    "\n",
    "matcher.add('ohne_zu__inf', [[{'ORTH': 'ohne'}, \n",
    "                              {'IS_ALPHA': True, \"OP\": \"*\"}, \n",
    "                              {'ORTH': 'zu'}, \n",
    "                              {'POS': 'VERB', 'OP': '+'}]], \n",
    "            # on_match=add_span_attributes\n",
    "            # on_match=Span.set_extension('ohne_zu__inf', force=True, getter=lambda span: True if 'ohne' in span.text else False)\n",
    "            )\n",
    "\n",
    "matcher.add('zu__inf__sein', [[{\"POS\": \"AUX\", \"LEMMA\": {\"IN\": [\"sein\"]}}, \n",
    "                               {'IS_ALPHA': True, \"OP\": \"*\"}, \n",
    "                               {'LEMMA': 'zu'}, \n",
    "                               {'POS': 'VERB', 'OP': '+'}]], \n",
    "            # on_match=add_span_attributes\n",
    "            # on_match=Span.set_extension('zu__inf__sein', force=True, getter=lambda span: True if 'ist' in span.text else False)\n",
    "            )\n",
    "\n",
    "matcher.pipe(de_doc, as_tuples=True)\n",
    "matches = matcher(de_doc)\n",
    "\n",
    "\n",
    "de_doc.spans['custom'] = [\n",
    "    # Span(de_doc, 2, 5, 'ΝΟΜ'),\n",
    "    # Span(de_doc, 5, 6, 'ΓΛΩ'),\n",
    "    # Span(de_doc, 8, 9, 'ΝΟΜ'),\n",
    "    # Span(de_doc, 9, 11, 'ΓΛΩ'),\n",
    "    # Span(de_doc, 12, 18, 'ΠΣΔ'),\n",
    "    # Span(de_doc, 17, 18, 'ΓΛΩ'),\n",
    "]\n",
    "\n",
    "# make sure the next iteration doesn't match the same tokens again\n",
    "unique_matches = []\n",
    "for match_text, start, end in matches:\n",
    "    if start not in [start for _, start, end in unique_matches]:\n",
    "        unique_matches.append((match_text, start, end))\n",
    "\n",
    "for match_id, start, end in unique_matches:\n",
    "    string_id = de_doc.vocab.strings[match_id]\n",
    "    span = de_doc[start:end]\n",
    "    print()\n",
    "    display(HTML(f'<strong>{span.text}</strong> (<code>{string_id}</code>)'))\n",
    "    # append the span to the list of spans\n",
    "    de_doc.spans['custom'].append(span)\n",
    "\n",
    "# print(\"Noun phrases:\", '\\n'.join([chunk.text for chunk in de_doc.noun_chunks]), sep='\\n' + '-'*25 +'\\n', end='\\n\\n')\n",
    "# print(de_doc.spans['custom'])\n",
    "\n",
    "print('ohne zu _inf_:', [de_doc[start:end].text for _, start, end in matches if de_doc[start:end]._.ohne_zu__inf])\n",
    "print('zu _inf_ sein:', [de_doc[start:end].text for _, start, end in matches if de_doc[start:end]._.zu__inf__sein])\n",
    "\n",
    "# print('ohne zu _inf_:', list(set([span.text for span in de_doc.spans['custom'] if span._.ohne_zu__inf])))\n",
    "# print('zu _inf_ sein:', list(set([span.text for span in de_doc.spans['custom'] if span._.zu__inf__sein])))\n",
    "\n",
    "\n",
    "# custom spans\n",
    "de_doc.spans['custom'] = [\n",
    "    Span(de_doc, 2, 5, 'ΝΟΜ'),\n",
    "    Span(de_doc, 5, 6, 'ΓΛΩ'),\n",
    "    Span(de_doc, 8, 9, 'ΝΟΜ'),\n",
    "    Span(de_doc, 9, 11, 'ΓΛΩ'),\n",
    "    Span(de_doc, 12, 18, 'ΠΣΔ'),\n",
    "    Span(de_doc, 17, 18, 'ΓΛΩ'),\n",
    "] + list(de_doc.spans['custom'])\n",
    "\n",
    "options = {\n",
    "    'spans_key': 'custom', \n",
    "    'colors': {\n",
    "        'ΝΟΜ': '#79b8e1', \n",
    "        'ΓΛΩ': '#ffa147', \n",
    "        'ΠΣΔ': '#9f8df0'\n",
    "    },\n",
    "}\n",
    "\n",
    "displacy.render(de_doc, style='span', options=options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
